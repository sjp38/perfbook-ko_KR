% defer/defer.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\QuickQuizChapter{chp:Deferred Processing}{Deferred Processing}
%
\Epigraph{All things come to those who wait.}{\emph{Violet Fane}}

일을 뒤로 미루는 전략은 기록된 역사의 시작 전까지 이어져 있습니다.
이것은 자주 미루기나 완전한 게으름으로 여겨져 비웃음을 받아왔습니다.
하지만, 지난 수십년간 사람들은 병렬 알고리즘들의 단순화와 능률화에 있어서의 이
전략의 가치를 깨달았습니다~\cite{Kung80,HMassalinPhD}.
이걸 믿든 믿지 않든, 병렬 프로그래밍에서의 ``게으름'' 은 종종 근면성에 비해
성능과 확장성이 좋습니다!
이런 성능과 확장성에서의 장점은 일을 뒤로 미루는 것은 종종 동기화 기능들을
약화시키는게 가능하게 하고, 따라서 동기화 오버헤드를 줄이게 된다는 사실에서
기인합니다.
일을 뒤로 미루는 일반적인 전략은
레퍼런스 카운팅 (Section~\ref{sec:defer:Reference Counting}),
해저드 포인터 (Section~\ref{sec:defer:Hazard Pointers}),
순차적 락킹 (Section~\ref{sec:defer:Sequence Locks}),
그리고 RCU (Section~\ref{sec:defer:Read-Copy Update (RCU)}) 등을 포함합니다.
마지막으로, Section~\ref{sec:defer:Which to Choose?}
에서는 이 챕터에서 다루어진 일 뒤로 미루기 전략들 가운데 어떻게 선택을 해야
하는지 이야기 하고, 
Section~\ref{sec:defer:What About Updates?} 에서는 업데이트의 역할에 대해
논합니다.
\iffalse

The strategy of deferring work goes back before the dawn of recorded
history. It has occasionally been derided as procrastination or
even as sheer laziness.
However, in the last few decades workers have recognized this strategy's value
in simplifying and streamlining parallel algorithms~\cite{Kung80,HMassalinPhD}.
Believe it or not, ``laziness'' in parallel programming often outperforms and
out-scales industriousness!
These performance and scalability benefits stem from the fact that
deferring work often enables weakening of synchronization primitives,
thereby reducing synchronization overhead.
General approaches of work deferral include
reference counting (Section~\ref{sec:defer:Reference Counting}),
hazard pointers (Section~\ref{sec:defer:Hazard Pointers}),
sequence locking (Section~\ref{sec:defer:Sequence Locks}),
and RCU (Section~\ref{sec:defer:Read-Copy Update (RCU)}).
Finally, Section~\ref{sec:defer:Which to Choose?}
describes how to choose among the work-deferral schemes covered in
this chapter and Section~\ref{sec:defer:What About Updates?}
discusses the role of updates.
\fi

하지만 먼저 이런 방법들을 비교하고 대비하는데에 사용될 예제 알고리즘을
소개하겠습니다.
\iffalse

But first we will introduce an example algorithm that will be used
to compare and contrast these approaches.
\fi

\section{Running Example}
\label{sec:defer:Running Example}

이 챕터는 이런 접근법들의 가치를 보이고 또 그것들을 서로 비교할 수 있도록 하기
위해 단순화된 패킷 라우팅 알고리즘을 사용할 겁니다.
라우팅 알고리즘은 운영체제 커널에서 각각의 바깥으로 나가는 TCP/IP 패킷들을
알맞는 네트워크 인터페이스로 전달하는데에 사용됩니다.
이 특정한 알고리즘은 고전적인 1980년대의 packet-train-optimized 알고리즘으로
BSD UNIX~\cite{VanJacobson88} 에서 사용되었으며, 단순한 링크드 리스트로
구성되었습니다.\footnote{
	달리 말하자면, 이건 OpenBSD, NetBSD 도 아니고 심지어 FreeBSD 도
	아니었고 Pre-BSD 였습니다.}
최신 라우팅 알고리즘들은 더 복잡한 데이터 구조를 사용합니다만,
Chapter~\ref{chp:Counting} 에서와 같이, 극단적으로 간단한 알고리즘이 극단적으로
이해하기 쉬운 구성에서의 병렬성에 특정된 문제들을 밝히는데 도움을 줄 것입니다.
\iffalse

This chapter will use a simplified packet-routing algorithm to demonstrate
the value of these approaches and to allow them to be compared.
Routing algorithms are used in operating-system kernels to
deliver each outgoing TCP/IP packets to the appropriate network interface.
This particular algorithm is a simplified version of the classic 1980s
packet-train-optimized algorithm used in BSD UNIX~\cite{VanJacobson88},
consisting of a simple linked list.\footnote{
	In other words, this is not OpenBSD, NetBSD, or even
	FreeBSD, but none other than Pre-BSD.}
Modern routing algorithms use more complex data structures, however, as in
Chapter~\ref{chp:Counting}, a simple algorithm will
help highlight issues specific to parallelism in an
easy-to-understand setting.
\fi

우리는 더 나아가서 출발지와 목적지 IP 주소와 포트들 네가지 정보로 구성되는 검색
키를 간단한 정수로 교체함으로써 알고리즘을 더욱 단순화할 겁니다.
검색되고 리턴되는 값 또한 간단한 정수로 바꿔질 것이어서, 데이터 구조는
Figure~\ref{fig:defer:Pre-BSD Packet Routing List} 에서와 같이 될건데,
이 그림대로라면 address~42 의 패킷을 interface~1 로, address~56 의 패킷을
interface~2 로, 그리고 address~17 의 패킷을 interface~7 로 전달할 겁니다.
외부의 패킷 네트워크는 안정적일 것을 가정하면, 이 리스트는 매우 자주 검색되고
아주 가끔씩만 업데이트 될 것입니다.
Chapter~\ref{chp:Hardware and its Habits} 에서 우리는, 빛의 제한된 속도와
물질의 원자성의 자연적 법칙과 같은 불편한 물리 법칙을 회피하는 가장 좋은 방법은
데이터를 쪼개거나 읽기가 대부분인 공유에 기대는 것임을 배웠습니다.
이 챕터에서, 우리는 이 Pre-BSD 패킷 라우팅 리스트를 사용해 읽기가 대부분인
상황을 위한 동기화 기법을 평가해 보도록 하겠습니다.
\iffalse

We further simplify the algorithm by reducing the search key from
a quadruple consisting of source and destination IP addresses and
ports all the way down to a simple integer.
The value looked up and returned will also be a simple integer,
so that the data structure is as shown in
Figure~\ref{fig:defer:Pre-BSD Packet Routing List}, which
directs packets with address~42 to interface~1, address~56 to
interface~3, and address~17 to interface~7.
Assuming that external packet network is stable,
this list will be searched frequently and updated rarely.
In Chapter~\ref{chp:Hardware and its Habits}
we learned that the best ways to evade inconvenient laws of physics, such as
the finite speed of light and the atomic nature of matter, is to
either partition the data or to rely on read-mostly sharing.
In this chapter, we will use this Pre-BSD packet routing
list to evaluate a number of read-mostly synchronization techniques.
\fi

\begin{figure}[tb]
\begin{center}
\resizebox{3in}{!}{\includegraphics{defer/RouteList}}
\end{center}
\caption{Pre-BSD Packet Routing List}
\label{fig:defer:Pre-BSD Packet Routing List}
\end{figure}

\begin{figure}[tb]
{ \scriptsize
\begin{verbbox}
 1 struct route_entry {
 2   struct cds_list_head re_next;
 3   unsigned long addr;
 4   unsigned long iface;
 5 };
 6 CDS_LIST_HEAD(route_list);
 7
 8 unsigned long route_lookup(unsigned long addr)
 9 {
10   struct route_entry *rep;
11   unsigned long ret;
12
13   cds_list_for_each_entry(rep,
14                           &route_list, re_next) {
15     if (rep->addr == addr) {
16       ret = rep->iface;
17       return ret;
18     }
19   }
20   return ULONG_MAX;
21 }
22
23 int route_add(unsigned long addr,
24               unsigned long interface)
25 {
26   struct route_entry *rep;
27
28   rep = malloc(sizeof(*rep));
29   if (!rep)
30     return -ENOMEM;
31   rep->addr = addr;
32   rep->iface = interface;
33   cds_list_add(&rep->re_next, &route_list);
34   return 0;
35 }
36
37 int route_del(unsigned long addr)
38 {
39   struct route_entry *rep;
40
41   cds_list_for_each_entry(rep,
42                           &route_list, re_next) {
43     if (rep->addr == addr) {
44       cds_list_del(&rep->re_next);
45       free(rep);
46       return 0;
47     }
48   }
49   return -ENOENT;
50 }
\end{verbbox}
}
\centering
\theverbbox
\caption{Sequential Pre-BSD Routing Table}
\label{fig:defer:Sequential Pre-BSD Routing Table}
\end{figure}

Figure~\ref{fig:defer:Sequential Pre-BSD Routing Table} 는
Figure~\ref{fig:defer:Pre-BSD Packet Routing List} 에 연관되는 간단한 싱글
쓰레드 구현을 보입니다.
Line~1-5 는 \co{route_entry} 구조체를 정의하고 line~6 는 \co{route_list} 헤더를
정의합니다.
Line~8-21 은 \co{route_lookup()} 을 정의하는데, 이 함수는 순차적으로
\co{route_list} 를 검색하고 검색에 성공하면 연관되는 \co{->iface} 를 리턴하고,
검색에 실패하면 \co{ULONG_MAX} 를 리턴합니다.
Line~23-35 는 \co{route_add()} 를 정의하는데, 이 함수는 \co{route_entry}
구조체를 메모리 할당받고, 초기화 한 후, 리스트에 추가하는데 메모리 할당에
실패한 경우에는 \co{-ENOMEM} 을 리턴합니다.
마지막으로, line~37-50 은 \co{route_del()} 을 정의하는데, 이 함수는 특정
\co{route_entry} 구조체를 존재한다면 제거하고 그렇지 않다면 \co{-ENOENT} 를
리턴합니다.

이 싱글쓰레드 구현은 이 챕터 안의 다양한 동시성을 사용한 구현의 하나의 프로토
타입 역할을 하고, 또한 이상적인 성능과 확장성의 평가를 위한 역할도 합니다.
\iffalse

Figure~\ref{fig:defer:Sequential Pre-BSD Routing Table}
shows a simple single-threaded implementation corresponding to
Figure~\ref{fig:defer:Pre-BSD Packet Routing List}.
Lines~1-5 define a \co{route_entry} structure and line~6 defines
the \co{route_list} header.
Lines~8-21 define \co{route_lookup()}, which sequentially searches
\co{route_list}, returning the corresponding \co{->iface}, or
\co{ULONG_MAX} if there is no such route entry.
Lines~23-35 define \co{route_add()}, which allocates a
\co{route_entry} structure, initializes it, and adds it to the
list, returning \co{-ENOMEM} in case of memory-allocation failure.
Finally, lines~37-50 define \co{route_del()}, which removes and
frees the specified \co{route_entry} structure if it exists,
or returns \co{-ENOENT} otherwise.

This single-threaded implementation serves as a prototype for the various
concurrent implementations in this chapter, and also as an estimate of
ideal scalability and performance.
\fi

\input{defer/refcnt}
\input{defer/hazptr}
\input{defer/seqlock}
\input{defer/rcu}
\input{defer/rcuexercises}
\input{defer/whichtochoose}
\input{defer/updates}

% @@@ compare and contrast the various mechanisms.
